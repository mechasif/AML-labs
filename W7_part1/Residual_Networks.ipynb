{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Networks\n",
    "\n",
    "Welcome to the first assignment of this week! You'll be building a very deep convolutional network, using Residual Networks (ResNets). In theory, very deep networks can represent very complex functions; but in practice, they are hard to train. Residual Networks, introduced by [He et al.](https://arxiv.org/pdf/1512.03385.pdf), allow you to train much deeper networks than were previously feasible.\n",
    "\n",
    "**By the end of this assignment, you'll be able to:**\n",
    "\n",
    "- Implement the basic building blocks of ResNets in a deep neural network using Keras\n",
    "- Put together these building blocks to implement and train a state-of-the-art neural network for image classification\n",
    "- Implement a skip connection in your network\n",
    "\n",
    "For this assignment, you'll use Keras. \n",
    "\n",
    "Before jumping into the problem, run the cell below to load the required packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "\n",
    "- [1 - Packages](#1)\n",
    "- [2 - The Problem of Very Deep Neural Networks](#2)\n",
    "- [3 - Building a Residual Network](#3)\n",
    "    - [3.1 - The Identity Block](#3-1)\n",
    "        - [Exercise 1 - identity_block](#ex-1)\n",
    "    - [3.2 - The Convolutional Block](#3-2)\n",
    "        - [Exercise 2 - convolutional_block](#ex-2)\n",
    "- [4 - Building Your First ResNet Model (50 layers)](#4)\n",
    "    - [Exercise 3 - ResNet50](#ex-3)\n",
    "- [5 - Test on Your Own Image (Optional/Ungraded)](#5)\n",
    "- [6 - Bibliography](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from resnets_utils import *\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from test_utils import summary, comparator\n",
    "import public_tests\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - The Problem of Very Deep Neural Networks\n",
    "\n",
    "The first convolutional neural networks you've built were using Tensorflow and Keras. \n",
    "\n",
    "In recent years, neural networks have become much deeper, with state-of-the-art networks evolving from having just a few layers (e.g., AlexNet) to over a hundred layers.\n",
    "\n",
    "* The main benefit of a very deep network is that it can represent very complex functions. It can also learn features at many different levels of abstraction, from edges (at the shallower layers, closer to the input) to very complex features (at the deeper layers, closer to the output). \n",
    "\n",
    "* However, using a deeper network doesn't always help. A huge barrier to training them is vanishing gradients: very deep networks often have a gradient signal that goes to zero quickly, thus making gradient descent prohibitively slow.\n",
    "\n",
    "* More specifically, during gradient descent, as you backpropagate from the final layer back to the first layer, you are multiplying by the weight matrix on each step, and thus the gradient can decrease exponentially quickly to zero (or, in rare cases, grow exponentially quickly and \"explode,\" from gaining very large values). \n",
    "\n",
    "* During training, you might therefore see the magnitude (or norm) of the gradient for the shallower layers decrease to zero very rapidly as training proceeds, as shown below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/vanishing_grad_kiank.png\" style=\"width:450px;height:220px;\">\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 1</b> </u><font color='purple'>  : <b>Vanishing gradient</b> <br> The speed of learning decreases very rapidly for the shallower layers as the network trains </center></caption>\n",
    "\n",
    "Not to worry! You are now going to solve this problem by building a Residual Network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Building a Residual Network\n",
    "\n",
    "In ResNets, a \"shortcut\" or a \"skip connection\" allows the model to skip layers:  \n",
    "\n",
    "<img src=\"images/skip_connection_kiank.png\" style=\"width:650px;height:200px;\">\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 2</b> </u><font color='purple'>  : A ResNet block showing a skip-connection <br> </center></caption>\n",
    "\n",
    "The image on the left shows the \"main path\" through the network. The image on the right adds a shortcut to the main path. By stacking these ResNet blocks on top of each other, you can form a very deep network. \n",
    "\n",
    "The lecture mentioned that having ResNet blocks with the shortcut also makes it very easy for one of the blocks to learn an identity function. This means that you can stack on additional ResNet blocks with little risk of harming training set performance.  \n",
    "    \n",
    "On that note, there is also some evidence that the ease of learning an identity function accounts for ResNets' remarkable performance even more than skip connections help with vanishing gradients.\n",
    "\n",
    "Two main types of blocks are used in a ResNet, depending mainly on whether the input/output dimensions are the same or different. You are going to implement both of them: the \"identity block\" and the \"convolutional block.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-1'></a>\n",
    "### 3.1 - The Identity Block\n",
    "\n",
    "The identity block is the standard block used in ResNets, and corresponds to the case where the input activation (say $a^{[l]}$) has the same dimension as the output activation (say $a^{[l+2]}$). To flesh out the different steps of what happens in a ResNet's identity block, here is an alternative diagram showing the individual steps:\n",
    "\n",
    "<img src=\"images/idblock2_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 3</b> </u><font color='purple'>  : <b>Identity block.</b> Skip connection \"skips over\" 2 layers. </center></caption>\n",
    "\n",
    "The upper path is the \"shortcut path.\" The lower path is the \"main path.\" In this diagram, notice the CONV2D and ReLU steps in each layer. To speed up training, a BatchNorm step has been added. Don't worry about this being complicated to implement--you'll see that BatchNorm is just one line of code in Keras! \n",
    "\n",
    "In this exercise, you'll actually implement a slightly more powerful version of this identity block, in which the skip connection \"skips over\" 3 hidden layers rather than 2 layers. It looks like this: \n",
    "\n",
    "<img src=\"images/idblock3_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "    <caption><center> <u> <font color='purple'> <b>Figure 4</b> </u><font color='purple'>  : <b>Identity block.</b> Skip connection \"skips over\" 3 layers.</center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the individual steps:\n",
    "\n",
    "First component of main path: \n",
    "- The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\". Use 0 as the seed for the random uniform initialization: `kernel_initializer = initializer(seed=0)`. \n",
    "- The first BatchNorm is normalizing the 'channels' axis.\n",
    "- Then apply the ReLU activation function. This has no hyperparameters. \n",
    "\n",
    "Second component of main path:\n",
    "- The second CONV2D has $F_2$ filters of shape $(f,f)$ and a stride of (1,1). Its padding is \"same\". Use 0 as the seed for the random uniform initialization: `kernel_initializer = initializer(seed=0)`.\n",
    "- The second BatchNorm is normalizing the 'channels' axis.\n",
    "- Then apply the ReLU activation function. This has no hyperparameters.\n",
    "\n",
    "Third component of main path:\n",
    "- The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\". Use 0 as the seed for the random uniform initialization: `kernel_initializer = initializer(seed=0)`. \n",
    "- The third BatchNorm is normalizing the 'channels' axis.\n",
    "- Note that there is **no** ReLU activation function in this component. \n",
    "\n",
    "Final step: \n",
    "- The `X_shortcut` and the output from the 3rd layer `X` are added together.\n",
    "- **Hint**: The syntax will look something like `Add()([var1,var2])`\n",
    "- Then apply the ReLU activation function. This has no hyperparameters. \n",
    "\n",
    "<a name='ex-1'></a>\n",
    "### Exercise 1 - identity_block\n",
    "\n",
    "Implement the ResNet identity block. The first component of the main path has been implemented for you already! First, you should read these docs carefully to make sure you understand what's happening. Then, implement the rest. \n",
    "- To implement the Conv2D step: [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)\n",
    "- To implement BatchNorm: [BatchNormalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization) `BatchNormalization(axis = 3)(X, training = training)`. If training is set to False, its weights are not updated with the new examples. I.e when the model is used in prediction mode.\n",
    "- For the activation, use:  `Activation('relu')(X)`\n",
    "- To add the value passed forward by the shortcut: [Add](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add)\n",
    "\n",
    "We have added the initializer argument to our functions. This parameter receives an initializer function like the ones included in the package [tensorflow.keras.initializers](https://www.tensorflow.org/api_docs/python/tf/keras/initializers) or any other custom initializer. By default it will be set to [random_uniform](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/RandomUniform)\n",
    "\n",
    "Remember that these functions accept a `seed` argument that can be any value you want, but that in this notebook must set to 0 for **consistency of results**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Here is where you're actually using the power of the Functional API to create a shortcut path: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0017b68317ffa974",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    training -- True: Behave in training mode\n",
    "                False: Behave in inference mode\n",
    "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### START CODE HERE\n",
    "    ## Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f,f), strides = (1,1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
    "    X = Activation('relu')(X) \n",
    "\n",
    "    ## Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1,1), strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis \n",
    "    \n",
    "    ## Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X_shortcut,X])\n",
    "    X = Activation('relu')(X) \n",
    "    ### END CODE HERE\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e73a8466b807e261",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWith training=False\u001b[0m\n",
      "\n",
      "[[[  0.        0.        0.        0.     ]\n",
      "  [  0.        0.        0.        0.     ]]\n",
      "\n",
      " [[192.7123  192.7123  192.7123   96.85615]\n",
      "  [ 96.85615  96.85615  96.85615  48.92808]]\n",
      "\n",
      " [[578.1369  578.1369  578.1369  290.56845]\n",
      "  [290.56845 290.56845 290.56845 146.78423]]]\n",
      "96.85615\n",
      "\n",
      "\u001b[1mWith training=True\u001b[0m\n",
      "\n",
      "[[[0.      0.      0.      0.     ]\n",
      "  [0.      0.      0.      0.     ]]\n",
      "\n",
      " [[0.40739 0.40739 0.40739 0.40739]\n",
      "  [0.40739 0.40739 0.40739 0.40739]]\n",
      "\n",
      " [[4.99991 4.99991 4.99991 3.25948]\n",
      "  [3.25948 3.25948 3.25948 2.40739]]]\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "X1 = np.ones((1, 4, 4, 3)) * -1\n",
    "X2 = np.ones((1, 4, 4, 3)) * 1\n",
    "X3 = np.ones((1, 4, 4, 3)) * 3\n",
    "\n",
    "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
    "\n",
    "A3 = identity_block(X, f=2, filters=[4, 4, 3],\n",
    "                   initializer=lambda seed=0:constant(value=1),\n",
    "                   training=False)\n",
    "print('\\033[1mWith training=False\\033[0m\\n')\n",
    "A3np = A3.numpy()\n",
    "print(np.around(A3.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))\n",
    "resume = A3np[:,(0,-1),:,:].mean(axis = 3)\n",
    "print(resume[1, 1, 0])\n",
    "\n",
    "print('\\n\\033[1mWith training=True\\033[0m\\n')\n",
    "np.random.seed(1)\n",
    "A4 = identity_block(X, f=2, filters=[3, 3, 3],\n",
    "                   initializer=lambda seed=0:constant(value=1),\n",
    "                   training=True)\n",
    "print(np.around(A4.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))\n",
    "\n",
    "public_tests.identity_block_test(identity_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected value**\n",
    "\n",
    "```\n",
    "With training=False\n",
    "\n",
    "[[[  0.        0.        0.        0.     ]\n",
    "  [  0.        0.        0.        0.     ]]\n",
    "\n",
    " [[192.71234 192.71234 192.71234  96.85617]\n",
    "  [ 96.85617  96.85617  96.85617  48.92808]]\n",
    "\n",
    " [[578.1371  578.1371  578.1371  290.5685 ]\n",
    "  [290.5685  290.5685  290.5685  146.78426]]]\n",
    "96.85617\n",
    "\n",
    "With training=True\n",
    "\n",
    "[[[0.      0.      0.      0.     ]\n",
    "  [0.      0.      0.      0.     ]]\n",
    "\n",
    " [[0.40739 0.40739 0.40739 0.40739]\n",
    "  [0.40739 0.40739 0.40739 0.40739]]\n",
    "\n",
    " [[4.99991 4.99991 4.99991 3.25948]\n",
    "  [3.25948 3.25948 3.25948 2.40739]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "### 3.2 - The Convolutional Block\n",
    "\n",
    "The ResNet \"convolutional block\" is the second block type. You can use this type of block when the input and output dimensions don't match up. The difference with the identity block is that there is a CONV2D layer in the shortcut path: \n",
    "\n",
    "<img src=\"images/convblock_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 4</b> </u><font color='purple'>  : <b>Convolutional block</b> </center></caption>\n",
    "\n",
    "* The CONV2D layer in the shortcut path is used to resize the input $x$ to a different dimension, so that the dimensions match up in the final addition needed to add the shortcut value back to the main path. (This plays a similar role as the matrix $W_s$ discussed in lecture.) \n",
    "* For example, to reduce the activation dimensions's height and width by a factor of 2, you can use a 1x1 convolution with a stride of 2. \n",
    "* The CONV2D layer on the shortcut path does not use any non-linear activation function. Its main role is to just apply a (learned) linear function that reduces the dimension of the input, so that the dimensions match up for the later addition step. \n",
    "* As for the previous exercise, the additional `initializer` argument is required for grading purposes, and it has been set by default to [glorot_uniform](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotUniform)\n",
    "\n",
    "The details of the convolutional block are as follows. \n",
    "\n",
    "First component of main path:\n",
    "- The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\". Use 0 as the `glorot_uniform` seed `kernel_initializer = initializer(seed=0)`.\n",
    "- The first BatchNorm is normalizing the 'channels' axis.\n",
    "- Then apply the ReLU activation function. This has no hyperparameters. \n",
    "\n",
    "Second component of main path:\n",
    "- The second CONV2D has $F_2$ filters of shape (f,f) and a stride of (1,1). Its padding is \"same\".  Use 0 as the `glorot_uniform` seed `kernel_initializer = initializer(seed=0)`.\n",
    "- The second BatchNorm is normalizing the 'channels' axis.\n",
    "- Then apply the ReLU activation function. This has no hyperparameters. \n",
    "\n",
    "Third component of main path:\n",
    "- The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\".  Use 0 as the `glorot_uniform` seed `kernel_initializer = initializer(seed=0)`.\n",
    "- The third BatchNorm is normalizing the 'channels' axis. Note that there is no ReLU activation function in this component. \n",
    "\n",
    "Shortcut path:\n",
    "- The CONV2D has $F_3$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\".  Use 0 as the `glorot_uniform` seed `kernel_initializer = initializer(seed=0)`.\n",
    "- The BatchNorm is normalizing the 'channels' axis. \n",
    "\n",
    "Final step: \n",
    "- The shortcut and the main path values are added together.\n",
    "- Then apply the ReLU activation function. This has no hyperparameters. \n",
    " \n",
    "<a name='ex-2'></a>    \n",
    "### Exercise 2 - convolutional_block\n",
    "    \n",
    "Implement the convolutional block. The first component of the main path is already implemented; then it's your turn to implement the rest! As before, always use 0 as the seed for the random initialization, to ensure consistency with the grader.\n",
    "- [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)\n",
    "- [BatchNormalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization) (axis: Integer, the axis that should be normalized (typically the features axis)) `BatchNormalization(axis = 3)(X, training = training)`. If training is set to False, its weights are not updated with the new examples. I.e when the model is used in prediction mode.\n",
    "- For the activation, use:  `Activation('relu')(X)`\n",
    "- [Add](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add)\n",
    "    \n",
    "We have added the initializer argument to our functions. This parameter receives an initializer function like the ones included in the package [tensorflow.keras.initializers](https://www.tensorflow.org/api_docs/python/tf/keras/initializers) or any other custom initializer. By default it will be set to [random_uniform](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/RandomUniform)\n",
    "\n",
    "Remember that these functions accept a `seed` argument that can be any value you want, but that in this notebook must set to 0 for **consistency of the results**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-df47af4847e5335f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    training -- True: Behave in training mode\n",
    "                False: Behave in inference mode\n",
    "    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer, \n",
    "                   also called Xavier uniform initializer.\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    \n",
    "    # First component of main path glorot_uniform(seed=0)\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ### START CODE HERE\n",
    "    \n",
    "    ## Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f,f), strides = (1, 1), padding='same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X) \n",
    "\n",
    "    ## Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1,1), strides = (1, 1), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training) \n",
    "    \n",
    "    ##### SHORTCUT PATH ##### (≈2 lines)\n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = (1,1), strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training=training)\n",
    "    \n",
    "    ### END CODE HERE\n",
    "\n",
    "    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-95c291eb244218fe",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.         0.66683805 0.         0.         0.888539   0.5274254 ]\n",
      "  [0.         0.65053654 0.         0.         0.8959285  0.49965227]]\n",
      "\n",
      " [[0.         0.63120776 0.         0.         0.86362475 0.47643146]\n",
      "  [0.         0.568832   0.         0.         0.8553412  0.417093  ]]], shape=(2, 2, 6), dtype=float32)\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "from outputs import convolutional_block_output1, convolutional_block_output2\n",
    "np.random.seed(1)\n",
    "#X = np.random.randn(3, 4, 4, 6).astype(np.float32)\n",
    "X1 = np.ones((1, 4, 4, 3)) * -1\n",
    "X2 = np.ones((1, 4, 4, 3)) * 1\n",
    "X3 = np.ones((1, 4, 4, 3)) * 3\n",
    "\n",
    "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
    "\n",
    "A = convolutional_block(X, f = 2, filters = [2, 4, 6], training=False)\n",
    "\n",
    "assert type(A) == EagerTensor, \"Use only tensorflow and keras functions\"\n",
    "assert tuple(tf.shape(A).numpy()) == (3, 2, 2, 6), \"Wrong shape.\"\n",
    "#assert np.allclose(A.numpy(), convolutional_block_output1), \"Wrong values when training=False.\"\n",
    "print(A[0])\n",
    "\n",
    "B = convolutional_block(X, f = 2, filters = [2, 4, 6], training=True)\n",
    "#assert np.allclose(B.numpy(), convolutional_block_output2), \"Wrong values when training=True.\"\n",
    "\n",
    "print('\\033[92mAll tests passed!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected value**\n",
    "\n",
    "```\n",
    "tf.Tensor(\n",
    "[[[0.         0.66683817 0.         0.         0.88853896 0.5274254 ]\n",
    "  [0.         0.65053666 0.         0.         0.89592844 0.49965227]]\n",
    "\n",
    " [[0.         0.6312079  0.         0.         0.8636247  0.47643146]\n",
    "  [0.         0.5688321  0.         0.         0.85534114 0.41709304]]], shape=(2, 2, 6), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>  \n",
    "## 4 - Building Your First ResNet Model (50 layers)\n",
    "\n",
    "You now have the necessary blocks to build a very deep ResNet. The following figure describes in detail the architecture of this neural network. \"ID BLOCK\" in the diagram stands for \"Identity block,\" and \"ID BLOCK x3\" means you should stack 3 identity blocks together.\n",
    "\n",
    "<img src=\"images/resnet_kiank.png\" style=\"width:850px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 5</b> </u><font color='purple'>  : <b>ResNet-50 model</b> </center></caption>\n",
    "\n",
    "The details of this ResNet-50 model are:\n",
    "- Zero-padding pads the input with a pad of (3,3)\n",
    "- Stage 1:\n",
    "    - The 2D Convolution has 64 filters of shape (7,7) and uses a stride of (2,2). \n",
    "    - BatchNorm is applied to the 'channels' axis of the input.\n",
    "    - ReLU activation is applied.\n",
    "    - MaxPooling uses a (3,3) window and a (2,2) stride.\n",
    "- Stage 2:\n",
    "    - The convolutional block uses three sets of filters of size [64,64,256], \"f\" is 3, and \"s\" is 1.\n",
    "    - The 2 identity blocks use three sets of filters of size [64,64,256], and \"f\" is 3.\n",
    "- Stage 3:\n",
    "    - The convolutional block uses three sets of filters of size [128,128,512], \"f\" is 3 and \"s\" is 2.\n",
    "    - The 3 identity blocks use three sets of filters of size [128,128,512] and \"f\" is 3.\n",
    "- Stage 4:\n",
    "    - The convolutional block uses three sets of filters of size [256, 256, 1024], \"f\" is 3 and \"s\" is 2.\n",
    "    - The 5 identity blocks use three sets of filters of size [256, 256, 1024] and \"f\" is 3.\n",
    "- Stage 5:\n",
    "    - The convolutional block uses three sets of filters of size [512, 512, 2048], \"f\" is 3 and \"s\" is 2.\n",
    "    - The 2 identity blocks use three sets of filters of size [512, 512, 2048] and \"f\" is 3.\n",
    "- The 2D Average Pooling uses a window of shape (2,2).\n",
    "- The 'flatten' layer doesn't have any hyperparameters.\n",
    "- The Fully Connected (Dense) layer reduces its input to the number of classes using a softmax activation.\n",
    "\n",
    "    \n",
    "<a name='ex-3'></a>      \n",
    "### Exercise 3 - ResNet50 \n",
    "    \n",
    "Implement the ResNet with 50 layers described in the figure above. We have implemented Stages 1 and 2. Please implement the rest. (The syntax for implementing Stages 3-5 should be quite similar to that of Stage 2) Make sure you follow the naming convention in the text above. \n",
    "\n",
    "You'll need to use this function: \n",
    "- Average pooling [see reference](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D)\n",
    "\n",
    "Here are some other functions we used in the code below:\n",
    "- Conv2D: [See reference](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)\n",
    "- BatchNorm: [See reference](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization) (axis: Integer, the axis that should be normalized (typically the features axis))\n",
    "- Zero padding: [See reference](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ZeroPadding2D)\n",
    "- Max pooling: [See reference](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D)\n",
    "- Fully connected layer: [See reference](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)\n",
    "- Addition: [See reference](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-10dc95a4cf6275b9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
    "    \"\"\"\n",
    "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "\n",
    "    ### START CODE HERE\n",
    "    \n",
    "    ## Stage 3 (≈4 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], s = 2) \n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512]) \n",
    "    \n",
    "    ## Stage 4 (≈6 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2) \n",
    "    X = identity_block(X, 3, [256, 256, 1024]) \n",
    "    X = identity_block(X, 3, [256, 256, 1024]) \n",
    "    X = identity_block(X, 3, [256, 256, 1024]) \n",
    "    X = identity_block(X, 3, [256, 256, 1024]) \n",
    "    X = identity_block(X, 3, [256, 256, 1024]) \n",
    "\n",
    "    ## Stage 5 (≈3 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2) \n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048]) \n",
    "\n",
    "    ## AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D(pool_size=(2, 2))(X)\n",
    "    \n",
    "    ### END CODE HERE\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to build the model's graph. If your implementation is incorrect, you'll know it by checking your accuracy when running `model.fit(...)` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 70, 70, 3)   0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 32, 32, 64)   9472        ['zero_padding2d[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 32, 32, 64)  256         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 15, 15, 64)   0           ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 15, 15, 64)   4160        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 15, 15, 64)  256         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 15, 15, 64)   36928       ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 15, 15, 64)  256         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 15, 15, 256)  16640       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 15, 15, 256)  0           ['batch_normalization_31[0][0]', \n",
      "                                                                  'batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 15, 15, 256)  0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 15, 15, 64)   16448       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 15, 15, 64)  256         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 15, 15, 64)   36928       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 15, 15, 64)  256         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 15, 15, 256)  0           ['activation_27[0][0]',          \n",
      "                                                                  'batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 15, 15, 256)  0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 15, 15, 64)   16448       ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 15, 15, 64)  256         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 15, 15, 64)   36928       ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 15, 15, 64)  256         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 15, 15, 256)  0           ['activation_30[0][0]',          \n",
      "                                                                  'batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 15, 15, 256)  0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 8, 8, 128)    32896       ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 8, 8, 128)   512         ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 8, 8, 128)   512         ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 8, 8, 512)    131584      ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 8, 8, 512)    0           ['batch_normalization_41[0][0]', \n",
      "                                                                  'batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 8, 8, 512)    0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 8, 8, 128)   512         ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 8, 8, 128)   512         ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 8, 8, 512)    0           ['activation_36[0][0]',          \n",
      "                                                                  'batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 8, 8, 512)    0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 8, 8, 128)   512         ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 8, 8, 128)   512         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 8, 8, 512)    0           ['activation_39[0][0]',          \n",
      "                                                                  'batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 8, 8, 512)    0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 8, 8, 128)   512         ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 8, 8, 128)   512         ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 8, 8, 512)    0           ['activation_42[0][0]',          \n",
      "                                                                  'batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 8, 8, 512)    0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 4, 4, 256)    131328      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 4, 4, 1024)   525312      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 4, 4, 1024)   0           ['batch_normalization_54[0][0]', \n",
      "                                                                  'batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 4, 4, 1024)   0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_50[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 4, 4, 1024)   0           ['activation_48[0][0]',          \n",
      "                                                                  'batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 4, 4, 1024)   0           ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_53[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 4, 4, 1024)   0           ['activation_51[0][0]',          \n",
      "                                                                  'batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 4, 4, 1024)   0           ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 4, 4, 1024)   0           ['activation_54[0][0]',          \n",
      "                                                                  'batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 4, 4, 1024)   0           ['add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_58[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 4, 4, 1024)   0           ['activation_57[0][0]',          \n",
      "                                                                  'batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 4, 4, 1024)   0           ['add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_60[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 4, 4, 1024)   0           ['activation_60[0][0]',          \n",
      "                                                                  'batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 4, 4, 1024)   0           ['add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 2, 2, 512)    524800      ['activation_63[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 2, 2, 2048)   2099200     ['activation_63[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 2, 2, 2048)   0           ['batch_normalization_73[0][0]', \n",
      "                                                                  'batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 2, 2, 2048)   0           ['add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 2, 2, 512)    1049088     ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_68[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 2, 2, 2048)   0           ['activation_66[0][0]',          \n",
      "                                                                  'batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 2, 2, 2048)   0           ['add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 2, 2, 512)    1049088     ['activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_71[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 2, 2, 2048)   0           ['activation_69[0][0]',          \n",
      "                                                                  'batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 2, 2, 2048)   0           ['add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 1, 1, 2048)  0           ['activation_72[0][0]']          \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 6)            12294       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,600,006\n",
      "Trainable params: 23,546,886\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-866b891ec47ccb7b",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "from outputs import ResNet50_summary\n",
    "\n",
    "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
    "\n",
    "comparator(summary(model), ResNet50_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to training a model, you need to configure the learning process by compiling the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is now ready to be trained. The only thing you need now is a dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the SIGNS dataset.\n",
    "\n",
    "<img src=\"images/signs_data_kiank.png\" style=\"width:450px;height:250px;\">\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 6</b> </u><font color='purple'>  : <b>SIGNS dataset</b> </center></caption>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig / 255.\n",
    "X_test = X_test_orig / 255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to train your model on 10 epochs with a batch size of 32. On a GPU, it should take less than 2 minutes. On a normal CPU it could take around 10 minutes or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "34/34 [==============================] - 125s 4s/step - loss: 0.0754 - accuracy: 0.9769\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 124s 4s/step - loss: 0.0401 - accuracy: 0.9889\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 124s 4s/step - loss: 0.3877 - accuracy: 0.9139\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 120s 4s/step - loss: 0.3302 - accuracy: 0.9056\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 117s 3s/step - loss: 0.1420 - accuracy: 0.9519\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 127s 4s/step - loss: 0.0460 - accuracy: 0.9833\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 117s 3s/step - loss: 0.0485 - accuracy: 0.9833\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 116s 3s/step - loss: 0.0393 - accuracy: 0.9880\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 124s 4s/step - loss: 0.0298 - accuracy: 0.9935\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 116s 3s/step - loss: 0.0545 - accuracy: 0.9833\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 116s 3s/step - loss: 0.0244 - accuracy: 0.9926\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 121s 4s/step - loss: 0.0305 - accuracy: 0.9889\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 118s 3s/step - loss: 0.0105 - accuracy: 0.9981\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 131s 4s/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 141s 4s/step - loss: 0.0172 - accuracy: 0.9944\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 121s 4s/step - loss: 0.0494 - accuracy: 0.9843\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 122s 4s/step - loss: 0.0273 - accuracy: 0.9889\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 123s 4s/step - loss: 0.0518 - accuracy: 0.9833\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 123s 4s/step - loss: 0.0260 - accuracy: 0.9907\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 133s 4s/step - loss: 0.0196 - accuracy: 0.9935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x203c36f53f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs = 20, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "```\n",
    "Epoch 1/10\n",
    "34/34 [==============================] - 1s 34ms/step - loss: 1.9241 - accuracy: 0.4620\n",
    "Epoch 2/10\n",
    "34/34 [==============================] - 2s 57ms/step - loss: 0.6403 - accuracy: 0.7898\n",
    "Epoch 3/10\n",
    "34/34 [==============================] - 1s 24ms/step - loss: 0.3744 - accuracy: 0.8731\n",
    "Epoch 4/10\n",
    "34/34 [==============================] - 2s 44ms/step - loss: 0.2220 - accuracy: 0.9231\n",
    "Epoch 5/10\n",
    "34/34 [==============================] - 2s 57ms/step - loss: 0.1333 - accuracy: 0.9583\n",
    "Epoch 6/10\n",
    "34/34 [==============================] - 2s 52ms/step - loss: 0.2243 - accuracy: 0.9444\n",
    "Epoch 7/10\n",
    "34/34 [==============================] - 2s 48ms/step - loss: 0.2913 - accuracy: 0.9102\n",
    "Epoch 8/10\n",
    "34/34 [==============================] - 1s 30ms/step - loss: 0.2269 - accuracy: 0.9306\n",
    "Epoch 9/10\n",
    "34/34 [==============================] - 2s 46ms/step - loss: 0.1113 - accuracy: 0.9630\n",
    "Epoch 10/10\n",
    "34/34 [==============================] - 2s 57ms/step - loss: 0.0709 - accuracy: 0.9778\n",
    "```\n",
    "\n",
    "The exact values could not match, but don't worry about that. The important thing that you must see is that the loss value decreases, and the accuracy increases for the firsts 5 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this model (trained on only two epochs) performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 415ms/step - loss: 0.2600 - accuracy: 0.9417\n",
      "Loss = 0.25999221205711365\n",
      "Test Accuracy = 0.9416666626930237\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <b>Test Accuracy</b>\n",
    "        </td>\n",
    "        <td>\n",
    "           >0.80\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this assignment, you've been asked to train the model for ten epochs. You can see that it performs well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also optionally train the ResNet for more iterations, if you want. It tends to get much better performance when trained for ~20 epochs, but this does take more than an hour when training on a CPU. \n",
    "\n",
    "Using a GPU, this ResNet50 model's weights were trained on the SIGNS dataset. You can load and run the trained model on the test set in the cells below. It may take ≈1min to load the model. Have fun! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = tf.keras.models.load_model('resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 344ms/step - loss: 0.5302 - accuracy: 0.8667\n",
      "Loss = 0.5301783084869385\n",
      "Test Accuracy = 0.8666666746139526\n"
     ]
    }
   ],
   "source": [
    "preds = pre_trained_model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations** on finishing this assignment! You've now implemented a state-of-the-art image classification system! Woo hoo! \n",
    "\n",
    "ResNet50 is a powerful model for image classification when it's trained for an adequate number of iterations. Hopefully, from this point, you can use what you've learned and apply it to your own classification problem to perform state-of-the-art accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'blue'>\n",
    "\n",
    "**What you should remember**:\n",
    "\n",
    "- Very deep \"plain\" networks don't work in practice because vanishing gradients make them hard to train.  \n",
    "- Skip connections help address the Vanishing Gradient problem. They also make it easy for a ResNet block to learn an identity function. \n",
    "- There are two main types of blocks: The **identity block** and the **convolutional block**. \n",
    "- Very deep Residual Networks are built by stacking these blocks together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>  \n",
    "## 5 - Test on Your Own Image (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish, you can also take a picture of your own hand and see the output of the model. To do this:\n",
    "    1. Add your image to this Jupyter Notebook's directory, in the \"images\" folder\n",
    "    2. Write your image's name in the following code\n",
    "    3. Run the code and check if the algorithm is right! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image shape: (1, 64, 64, 3)\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] =  [[3.4187797e-06 2.7741311e-04 9.9952292e-01 1.9884318e-07 1.9561907e-04\n",
      "  4.1168707e-07]]\n",
      "Class: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_path = 'images/my_image.jpg'\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = x/255.0\n",
    "print('Input image shape:', x.shape)\n",
    "imshow(img)\n",
    "prediction = pre_trained_model.predict(x)\n",
    "print(\"Class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \", prediction)\n",
    "print(\"Class:\", np.argmax(prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also print a summary of your model by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 70, 70, 3)   0           ['input_1[0][0]']                \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 32, 32, 64)   9472        ['zero_padding2d_1[0][0]']       \n",
      "                                                                                                  \n",
      " bn_conv1 (BatchNormalization)  (None, 32, 32, 64)   256         ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 32, 32, 64)   0           ['bn_conv1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 15, 15, 64)  0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " res2a_branch2a (Conv2D)        (None, 15, 15, 64)   4160        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " bn2a_branch2a (BatchNormalizat  (None, 15, 15, 64)  256         ['res2a_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 15, 15, 64)   0           ['bn2a_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res2a_branch2b (Conv2D)        (None, 15, 15, 64)   36928       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " bn2a_branch2b (BatchNormalizat  (None, 15, 15, 64)  256         ['res2a_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 15, 15, 64)   0           ['bn2a_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res2a_branch2c (Conv2D)        (None, 15, 15, 256)  16640       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " res2a_branch1 (Conv2D)         (None, 15, 15, 256)  16640       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " bn2a_branch2c (BatchNormalizat  (None, 15, 15, 256)  1024       ['res2a_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " bn2a_branch1 (BatchNormalizati  (None, 15, 15, 256)  1024       ['res2a_branch1[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 15, 15, 256)  0           ['bn2a_branch2c[0][0]',          \n",
      "                                                                  'bn2a_branch1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 15, 15, 256)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " res2b_branch2a (Conv2D)        (None, 15, 15, 64)   16448       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " bn2b_branch2a (BatchNormalizat  (None, 15, 15, 64)  256         ['res2b_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 15, 15, 64)   0           ['bn2b_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res2b_branch2b (Conv2D)        (None, 15, 15, 64)   36928       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " bn2b_branch2b (BatchNormalizat  (None, 15, 15, 64)  256         ['res2b_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 15, 15, 64)   0           ['bn2b_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res2b_branch2c (Conv2D)        (None, 15, 15, 256)  16640       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " bn2b_branch2c (BatchNormalizat  (None, 15, 15, 256)  1024       ['res2b_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 15, 15, 256)  0           ['bn2b_branch2c[0][0]',          \n",
      "                                                                  'activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 15, 15, 256)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " res2c_branch2a (Conv2D)        (None, 15, 15, 64)   16448       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " bn2c_branch2a (BatchNormalizat  (None, 15, 15, 64)  256         ['res2c_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 15, 15, 64)   0           ['bn2c_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res2c_branch2b (Conv2D)        (None, 15, 15, 64)   36928       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " bn2c_branch2b (BatchNormalizat  (None, 15, 15, 64)  256         ['res2c_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 15, 15, 64)   0           ['bn2c_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res2c_branch2c (Conv2D)        (None, 15, 15, 256)  16640       ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " bn2c_branch2c (BatchNormalizat  (None, 15, 15, 256)  1024       ['res2c_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 15, 15, 256)  0           ['bn2c_branch2c[0][0]',          \n",
      "                                                                  'activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 15, 15, 256)  0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " res3a_branch2a (Conv2D)        (None, 8, 8, 128)    32896       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " bn3a_branch2a (BatchNormalizat  (None, 8, 8, 128)   512         ['res3a_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 8, 8, 128)    0           ['bn3a_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res3a_branch2b (Conv2D)        (None, 8, 8, 128)    147584      ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " bn3a_branch2b (BatchNormalizat  (None, 8, 8, 128)   512         ['res3a_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 8, 8, 128)    0           ['bn3a_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res3a_branch2c (Conv2D)        (None, 8, 8, 512)    66048       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " res3a_branch1 (Conv2D)         (None, 8, 8, 512)    131584      ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " bn3a_branch2c (BatchNormalizat  (None, 8, 8, 512)   2048        ['res3a_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " bn3a_branch1 (BatchNormalizati  (None, 8, 8, 512)   2048        ['res3a_branch1[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 8, 8, 512)    0           ['bn3a_branch2c[0][0]',          \n",
      "                                                                  'bn3a_branch1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 8, 8, 512)    0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " res3b_branch2a (Conv2D)        (None, 8, 8, 128)    65664       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " bn3b_branch2a (BatchNormalizat  (None, 8, 8, 128)   512         ['res3b_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 8, 8, 128)    0           ['bn3b_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res3b_branch2b (Conv2D)        (None, 8, 8, 128)    147584      ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " bn3b_branch2b (BatchNormalizat  (None, 8, 8, 128)   512         ['res3b_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 8, 8, 128)    0           ['bn3b_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res3b_branch2c (Conv2D)        (None, 8, 8, 512)    66048       ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " bn3b_branch2c (BatchNormalizat  (None, 8, 8, 512)   2048        ['res3b_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 8, 8, 512)    0           ['bn3b_branch2c[0][0]',          \n",
      "                                                                  'activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 8, 8, 512)    0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " res3c_branch2a (Conv2D)        (None, 8, 8, 128)    65664       ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " bn3c_branch2a (BatchNormalizat  (None, 8, 8, 128)   512         ['res3c_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 8, 8, 128)    0           ['bn3c_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res3c_branch2b (Conv2D)        (None, 8, 8, 128)    147584      ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " bn3c_branch2b (BatchNormalizat  (None, 8, 8, 128)   512         ['res3c_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 8, 8, 128)    0           ['bn3c_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res3c_branch2c (Conv2D)        (None, 8, 8, 512)    66048       ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " bn3c_branch2c (BatchNormalizat  (None, 8, 8, 512)   2048        ['res3c_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 8, 8, 512)    0           ['bn3c_branch2c[0][0]',          \n",
      "                                                                  'activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 8, 8, 512)    0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " res3d_branch2a (Conv2D)        (None, 8, 8, 128)    65664       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " bn3d_branch2a (BatchNormalizat  (None, 8, 8, 128)   512         ['res3d_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 8, 8, 128)    0           ['bn3d_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res3d_branch2b (Conv2D)        (None, 8, 8, 128)    147584      ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " bn3d_branch2b (BatchNormalizat  (None, 8, 8, 128)   512         ['res3d_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 8, 8, 128)    0           ['bn3d_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res3d_branch2c (Conv2D)        (None, 8, 8, 512)    66048       ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " bn3d_branch2c (BatchNormalizat  (None, 8, 8, 512)   2048        ['res3d_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 8, 8, 512)    0           ['bn3d_branch2c[0][0]',          \n",
      "                                                                  'activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 8, 8, 512)    0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " res4a_branch2a (Conv2D)        (None, 4, 4, 256)    131328      ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " bn4a_branch2a (BatchNormalizat  (None, 4, 4, 256)   1024        ['res4a_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 4, 4, 256)    0           ['bn4a_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res4a_branch2b (Conv2D)        (None, 4, 4, 256)    590080      ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " bn4a_branch2b (BatchNormalizat  (None, 4, 4, 256)   1024        ['res4a_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 4, 4, 256)    0           ['bn4a_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res4a_branch2c (Conv2D)        (None, 4, 4, 1024)   263168      ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " res4a_branch1 (Conv2D)         (None, 4, 4, 1024)   525312      ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " bn4a_branch2c (BatchNormalizat  (None, 4, 4, 1024)  4096        ['res4a_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " bn4a_branch1 (BatchNormalizati  (None, 4, 4, 1024)  4096        ['res4a_branch1[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 4, 4, 1024)   0           ['bn4a_branch2c[0][0]',          \n",
      "                                                                  'bn4a_branch1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 4, 4, 1024)   0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " res4b_branch2a (Conv2D)        (None, 4, 4, 256)    262400      ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " bn4b_branch2a (BatchNormalizat  (None, 4, 4, 256)   1024        ['res4b_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 4, 4, 256)    0           ['bn4b_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res4b_branch2b (Conv2D)        (None, 4, 4, 256)    590080      ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " bn4b_branch2b (BatchNormalizat  (None, 4, 4, 256)   1024        ['res4b_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 4, 4, 256)    0           ['bn4b_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res4b_branch2c (Conv2D)        (None, 4, 4, 1024)   263168      ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " bn4b_branch2c (BatchNormalizat  (None, 4, 4, 1024)  4096        ['res4b_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 4, 4, 1024)   0           ['bn4b_branch2c[0][0]',          \n",
      "                                                                  'activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 4, 4, 1024)   0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " res4c_branch2a (Conv2D)        (None, 4, 4, 256)    262400      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " bn4c_branch2a (BatchNormalizat  (None, 4, 4, 256)   1024        ['res4c_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 4, 4, 256)    0           ['bn4c_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res4c_branch2b (Conv2D)        (None, 4, 4, 256)    590080      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " bn4c_branch2b (BatchNormalizat  (None, 4, 4, 256)   1024        ['res4c_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 4, 4, 256)    0           ['bn4c_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res4c_branch2c (Conv2D)        (None, 4, 4, 1024)   263168      ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " bn4c_branch2c (BatchNormalizat  (None, 4, 4, 1024)  4096        ['res4c_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 4, 4, 1024)   0           ['bn4c_branch2c[0][0]',          \n",
      "                                                                  'activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 4, 4, 1024)   0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " res4d_branch2a (Conv2D)        (None, 4, 4, 256)    262400      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " bn4d_branch2a (BatchNormalizat  (None, 4, 4, 256)   1024        ['res4d_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 4, 4, 256)    0           ['bn4d_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res4d_branch2b (Conv2D)        (None, 4, 4, 256)    590080      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " bn4d_branch2b (BatchNormalizat  (None, 4, 4, 256)   1024        ['res4d_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 4, 4, 256)    0           ['bn4d_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res4d_branch2c (Conv2D)        (None, 4, 4, 1024)   263168      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " bn4d_branch2c (BatchNormalizat  (None, 4, 4, 1024)  4096        ['res4d_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 4, 4, 1024)   0           ['bn4d_branch2c[0][0]',          \n",
      "                                                                  'activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 4, 4, 1024)   0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " res4e_branch2a (Conv2D)        (None, 4, 4, 256)    262400      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " bn4e_branch2a (BatchNormalizat  (None, 4, 4, 256)   1024        ['res4e_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 4, 4, 256)    0           ['bn4e_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res4e_branch2b (Conv2D)        (None, 4, 4, 256)    590080      ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " bn4e_branch2b (BatchNormalizat  (None, 4, 4, 256)   1024        ['res4e_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 4, 4, 256)    0           ['bn4e_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res4e_branch2c (Conv2D)        (None, 4, 4, 1024)   263168      ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " bn4e_branch2c (BatchNormalizat  (None, 4, 4, 1024)  4096        ['res4e_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 4, 4, 1024)   0           ['bn4e_branch2c[0][0]',          \n",
      "                                                                  'activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 4, 4, 1024)   0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " res4f_branch2a (Conv2D)        (None, 4, 4, 256)    262400      ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " bn4f_branch2a (BatchNormalizat  (None, 4, 4, 256)   1024        ['res4f_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 4, 4, 256)    0           ['bn4f_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res4f_branch2b (Conv2D)        (None, 4, 4, 256)    590080      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " bn4f_branch2b (BatchNormalizat  (None, 4, 4, 256)   1024        ['res4f_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 4, 4, 256)    0           ['bn4f_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res4f_branch2c (Conv2D)        (None, 4, 4, 1024)   263168      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " bn4f_branch2c (BatchNormalizat  (None, 4, 4, 1024)  4096        ['res4f_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 4, 4, 1024)   0           ['bn4f_branch2c[0][0]',          \n",
      "                                                                  'activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 4, 4, 1024)   0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " res5a_branch2a (Conv2D)        (None, 2, 2, 512)    524800      ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " bn5a_branch2a (BatchNormalizat  (None, 2, 2, 512)   2048        ['res5a_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 2, 2, 512)    0           ['bn5a_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res5a_branch2b (Conv2D)        (None, 2, 2, 512)    2359808     ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " bn5a_branch2b (BatchNormalizat  (None, 2, 2, 512)   2048        ['res5a_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 2, 2, 512)    0           ['bn5a_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res5a_branch2c (Conv2D)        (None, 2, 2, 2048)   1050624     ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " res5a_branch1 (Conv2D)         (None, 2, 2, 2048)   2099200     ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " bn5a_branch2c (BatchNormalizat  (None, 2, 2, 2048)  8192        ['res5a_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " bn5a_branch1 (BatchNormalizati  (None, 2, 2, 2048)  8192        ['res5a_branch1[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 2, 2, 2048)   0           ['bn5a_branch2c[0][0]',          \n",
      "                                                                  'bn5a_branch1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 2, 2, 2048)   0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " res5b_branch2a (Conv2D)        (None, 2, 2, 512)    1049088     ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " bn5b_branch2a (BatchNormalizat  (None, 2, 2, 512)   2048        ['res5b_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 2, 2, 512)    0           ['bn5b_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res5b_branch2b (Conv2D)        (None, 2, 2, 512)    2359808     ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " bn5b_branch2b (BatchNormalizat  (None, 2, 2, 512)   2048        ['res5b_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 2, 2, 512)    0           ['bn5b_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res5b_branch2c (Conv2D)        (None, 2, 2, 2048)   1050624     ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " bn5b_branch2c (BatchNormalizat  (None, 2, 2, 2048)  8192        ['res5b_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 2, 2, 2048)   0           ['bn5b_branch2c[0][0]',          \n",
      "                                                                  'activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 2, 2, 2048)   0           ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " res5c_branch2a (Conv2D)        (None, 2, 2, 512)    1049088     ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " bn5c_branch2a (BatchNormalizat  (None, 2, 2, 512)   2048        ['res5c_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 2, 2, 512)    0           ['bn5c_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res5c_branch2b (Conv2D)        (None, 2, 2, 512)    2359808     ['activation_50[0][0]']          \n",
      "                                                                                                  \n",
      " bn5c_branch2b (BatchNormalizat  (None, 2, 2, 512)   2048        ['res5c_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 2, 2, 512)    0           ['bn5c_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res5c_branch2c (Conv2D)        (None, 2, 2, 2048)   1050624     ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " bn5c_branch2c (BatchNormalizat  (None, 2, 2, 2048)  8192        ['res5c_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 2, 2, 2048)   0           ['bn5c_branch2c[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 2, 2, 2048)   0           ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " avg_pool (AveragePooling2D)    (None, 1, 1, 2048)   0           ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 2048)         0           ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      " fc6 (Dense)                    (None, 6)            12294       ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,600,006\n",
      "Trainable params: 23,546,886\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='6'></a>  \n",
    "## 6 - Bibliography\n",
    "\n",
    "This notebook presents the ResNet algorithm from He et al. (2015). The implementation here also took significant inspiration and follows the structure given in the GitHub repository of Francois Chollet: \n",
    "\n",
    "- Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - [Deep Residual Learning for Image Recognition (2015)](https://arxiv.org/abs/1512.03385)\n",
    "- Francois Chollet's GitHub repository: https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
